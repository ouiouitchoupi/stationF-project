# -*- coding: utf-8 -*-
"""model_contextual.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12R2abHr7Q_25GZZ9Tv0Sf2IzbfCzw3KC
"""

!pip install pandas scikit-learn matplotlib seaborn joblib

# ==========================================
# üöÄ IMPORTS ET CHARGEMENT DU DATASET
# ==========================================

from google.colab import files
uploaded = files.upload()  # ‚Üê charge ton data_train_nettoye.json

import pandas as pd
import numpy as np
import random
import joblib
from pathlib import Path

# Machine learning
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.preprocessing import OneHotEncoder

# NLP
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Visualisation
import matplotlib.pyplot as plt

# Chargement du dataset
DATA_PATH = list(uploaded.keys())[0]
df = pd.read_json(DATA_PATH)
print(f"‚úÖ Dataset charg√© ({len(df)} lignes)")
df.head(2)

# ==========================================
# üß† OUTILS D‚ÄôANALYSE DE PROFIL
# ==========================================

DEGREE_LEVEL_SCORES = {
    "Certificat": 0.7,
    "Licence": 0.9,
    "Ma√Ætrise": 1.0,
    "Master": 1.0,
    "Doctorat": 1.2,
}

PRESTIGIOUS_SCHOOLS = [
    "Polytechnique", "ENS", "Sorbonne", "√âcole 42", "HEC", "CentraleSup√©lec", "T√©l√©com Paris"
]

DOMAIN_KEYWORDS = {
    "informatique": ["programmation", "d√©veloppement", "python", "web", "java", "react", "c++", "ia", "html", "css"],
    "maths": ["alg√®bre", "analyse", "probabilit√©s", "statistiques", "g√©om√©trie", "calcul", "mod√©lisation"],
    "fran√ßais": ["litt√©rature", "r√©daction", "grammaire", "langue", "orthographe", "expression"],
    "physique": ["√©lectricit√©", "m√©canique", "thermodynamique", "optique"],
    "chimie": ["mol√©cules", "r√©actions", "chimique", "mati√®re"],
    "histoire": ["civilisation", "g√©ographie", "soci√©t√©", "culture", "politique"]
}

def compute_similarity(text_a: str, text_b: str) -> float:
    """Similitude TF-IDF simple (corrig√© : pas de stop_words='french')"""
    if not text_a or not text_b:
        return 0.0
    vectorizer = TfidfVectorizer(stop_words=None)
    tfidf = vectorizer.fit_transform([text_a, text_b])
    return float(cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0])

def compute_degree_score(diplomas: list) -> float:
    if not diplomas:
        return 1.0
    scores = [DEGREE_LEVEL_SCORES.get(d.get("level", ""), 1.0) for d in diplomas]
    return round(np.mean(scores), 2)

def compute_prestige_score(experiences: list) -> float:
    if not experiences:
        return 0.0
    count = 0
    for e in experiences:
        company = e.get("company", "").lower()
        if any(p.lower() in company for p in PRESTIGIOUS_SCHOOLS):
            count += 1
    return round(count / len(experiences), 2)

def extract_domain_from_text(text: str) -> str:
    text = text.lower()
    domain_scores = {d: sum(k in text for k in kws) for d, kws in DOMAIN_KEYWORDS.items()}
    return max(domain_scores, key=domain_scores.get)

# ==========================================
# üß© G√âN√âRATION DE DONN√âES SYNTH√âTIQUES R√âALISTES
# ==========================================

def simulate_course_pairings(df):
    simulated = []
    for _, prof in df.iterrows():
        base = prof.to_dict()
        profile_text = " ".join([
            base.get("description", ""),
            " ".join(d.get("title", "") for d in base.get("diplomas", [])),
            " ".join(e.get("title", "") for e in base.get("experiences", []))
        ])
        prof_domain = extract_domain_from_text(profile_text)

        # G√©n√©rer une combinaison pour chaque domaine possible
        for domain_name, keywords in DOMAIN_KEYWORDS.items():
            course_text = " ".join(keywords)
            sim = compute_similarity(profile_text, course_text)

            # Base de la note : forte si domaines identiques, sinon basse
            base_note = 4.6 if domain_name == prof_domain else 2.7
            note = base_note + np.random.normal(0, 0.3)  # petit bruit al√©atoire r√©aliste
            note = max(1.0, min(5.0, note))

            simulated.append({
                "professorId": base.get("professorId"),
                "prof_domain": prof_domain,
                "course_domain": domain_name,
                "similarity": sim,
                "degree_score": compute_degree_score(base.get("diplomas", [])),
                "prestige_score": compute_prestige_score(base.get("experiences", [])),
                "n_experiences": len(base.get("experiences", [])),
                "n_diplomas": len(base.get("diplomas", [])),
                "avg_stars": np.mean([c.get("numberOfStars", 4.0) for c in base.get("pastCourses", [])]),
                "target": round(note, 2)
            })
    return pd.DataFrame(simulated)

synthetic_df = simulate_course_pairings(df)
print(f"‚úÖ Donn√©es synth√©tiques g√©n√©r√©es : {synthetic_df.shape}")
synthetic_df.head()

# ==========================================
# üßÆ ENTRA√éNEMENT DU MOD√àLE CONTEXTUEL
# ==========================================

# Encodage des domaines de cours et prof
synthetic_df = pd.get_dummies(synthetic_df, columns=["prof_domain", "course_domain"])

X = synthetic_df.drop(columns=["target", "professorId"])
y = synthetic_df["target"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = GradientBoostingRegressor(n_estimators=400, learning_rate=0.05, max_depth=5, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"‚úÖ Mod√®le entra√Æn√© : MAE={mae:.3f}, R¬≤={r2:.3f}")

joblib.dump(model, "model_contextual_realistic.pkl")
print("üì¶ Mod√®le sauvegard√© : model_contextual_realistic.pkl")

# ==========================================
# üîÆ SIMULATION : PROF DE FRAN√áAIS SUR COURS PYTHON
# ==========================================

prof_fran√ßais = {
    "professorId": 999,
    "description": "Professeur de litt√©rature fran√ßaise passionn√© par la grammaire et la po√©sie.",
    "diplomas": [
        {"title": "Licence Lettres Modernes", "level": "Licence"},
        {"title": "Master en Linguistique", "level": "Master"}
    ],
    "experiences": [
        {"title": "Professeur de Fran√ßais", "company": "Sorbonne Universit√©"},
        {"title": "Chercheur en linguistique", "company": "Universit√© de Lyon"}
    ],
    "pastCourses": [
        {"title": "Grammaire avanc√©e", "numberOfStars": 4.8},
        {"title": "Analyse de texte litt√©raire", "numberOfStars": 4.7}
    ]
}

# Construire la ligne de features correspondante
profile_text = " ".join([
    prof_fran√ßais["description"],
    " ".join(d["title"] for d in prof_fran√ßais["diplomas"]),
    " ".join(e["title"] for e in prof_fran√ßais["experiences"])
])

prof_domain = extract_domain_from_text(profile_text)
course_domain = "informatique"
similarity = compute_similarity(profile_text, " ".join(DOMAIN_KEYWORDS[course_domain]))

features = {
    "similarity": similarity,
    "degree_score": compute_degree_score(prof_fran√ßais["diplomas"]),
    "prestige_score": compute_prestige_score(prof_fran√ßais["experiences"]),
    "n_experiences": len(prof_fran√ßais["experiences"]),
    "n_diplomas": len(prof_fran√ßais["diplomas"]),
    "avg_stars": np.mean([c["numberOfStars"] for c in prof_fran√ßais["pastCourses"]]),
}

# One-hot du domaine
for d in DOMAIN_KEYWORDS.keys():
    features[f"prof_domain_{d}"] = 1 if d == prof_domain else 0
    features[f"course_domain_{d}"] = 1 if d == course_domain else 0

# Pr√©diction
X_pred = pd.DataFrame([features])
for col in model.feature_names_in_:
    if col not in X_pred.columns:
        X_pred[col] = 0
X_pred = X_pred[model.feature_names_in_]

pred_score = model.predict(X_pred)[0]
print(f"‚≠ê Note pr√©dite pour un prof de {prof_domain} enseignant {course_domain} : {round(pred_score, 2)}/5")

# ==========================================
# ‚ö° SIMULATION : PROF DE PHYSIQUE SUR COURS DE FRAN√áAIS
# ==========================================

prof_physique = {
    "professorId": 1001,
    "description": "Professeur de physique exp√©rimentale sp√©cialis√© en m√©canique et thermodynamique. Passionn√© par la vulgarisation scientifique.",
    "diplomas": [
        {"title": "Master Physique", "level": "Master"},
        {"title": "Doctorat en √ânergie et Thermodynamique", "level": "Doctorat"}
    ],
    "experiences": [
        {"title": "Chercheur en √©nergie", "company": "CEA Grenoble"},
        {"title": "Professeur de Physique", "company": "Universit√© Grenoble Alpes"}
    ],
    "pastCourses": [
        {"title": "Thermodynamique appliqu√©e", "numberOfStars": 4.8},
        {"title": "M√©canique des fluides", "numberOfStars": 4.7}
    ]
}

# Construire la ligne de features correspondante
profile_text = " ".join([
    prof_physique["description"],
    " ".join(d["title"] for d in prof_physique["diplomas"]),
    " ".join(e["title"] for e in prof_physique["experiences"])
])

prof_domain = extract_domain_from_text(profile_text)
course_domain = "fran√ßais"
similarity = compute_similarity(profile_text, " ".join(DOMAIN_KEYWORDS[course_domain]))

features = {
    "similarity": similarity,
    "degree_score": compute_degree_score(prof_physique["diplomas"]),
    "prestige_score": compute_prestige_score(prof_physique["experiences"]),
    "n_experiences": len(prof_physique["experiences"]),
    "n_diplomas": len(prof_physique["diplomas"]),
    "avg_stars": np.mean([c["numberOfStars"] for c in prof_physique["pastCourses"]]),
}

# One-hot du domaine
for d in DOMAIN_KEYWORDS.keys():
    features[f"prof_domain_{d}"] = 1 if d == prof_domain else 0
    features[f"course_domain_{d}"] = 1 if d == course_domain else 0

# Pr√©diction
X_pred = pd.DataFrame([features])
for col in model.feature_names_in_:
    if col not in X_pred.columns:
        X_pred[col] = 0
X_pred = X_pred[model.feature_names_in_]

pred_score = model.predict(X_pred)[0]
print(f"‚≠ê Note pr√©dite pour un prof de {prof_domain} enseignant {course_domain} : {round(pred_score, 2)}/5")

# ==========================================
# üíæ SAUVEGARDE ET T√âL√âCHARGEMENT DU MOD√àLE
# ==========================================
from google.colab import files
import shutil

# Nom du mod√®le (√† adapter selon ton entra√Ænement)
MODEL_NAME = "model_contextual_realistic.pkl"

# V√©rifie que le fichier existe
import os
if not os.path.exists(MODEL_NAME):
    raise FileNotFoundError(f"‚ùå Le mod√®le {MODEL_NAME} n'existe pas dans le dossier courant.")

# T√©l√©chargement direct depuis Colab
files.download(MODEL_NAME)

print(f"‚úÖ Mod√®le {MODEL_NAME} pr√™t √† √™tre t√©l√©charg√© sur ton ordinateur !")