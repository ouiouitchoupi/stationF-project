# -*- coding: utf-8 -*-
"""model_contextual.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12R2abHr7Q_25GZZ9Tv0Sf2IzbfCzw3KC
"""

!pip install pandas scikit-learn matplotlib seaborn joblib

# ==========================================
# üöÄ IMPORTS ET CHARGEMENT DU DATASET
# ==========================================

from google.colab import files
uploaded = files.upload()  # ‚Üê charge ton data_train_nettoye.json

import pandas as pd
import numpy as np
import random
import joblib
from pathlib import Path

# Machine learning
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.preprocessing import OneHotEncoder

# NLP
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Visualisation
import matplotlib.pyplot as plt

# Chargement du dataset
DATA_PATH = list(uploaded.keys())[0]
df = pd.read_json(DATA_PATH)
print(f"‚úÖ Dataset charg√© ({len(df)} lignes)")
df.head(2)

# ==========================================
# üß© G√âN√âRATION DE DONN√âES SYNTH√âTIQUES R√âALISTES
# ==========================================

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, r2_score
import joblib
from pathlib import Path

# Domaines et mots-cl√©s
DOMAIN_KEYWORDS = {
    "informatique": ["programmation", "d√©veloppement", "python", "web", "java", "ia", "html", "css"],
    "maths": ["alg√®bre", "analyse", "probabilit√©s", "statistiques"],
    "fran√ßais": ["litt√©rature", "r√©daction", "grammaire", "langue"],
    "physique": ["√©lectricit√©", "m√©canique", "thermodynamique"],
    "chimie": ["mol√©cule", "r√©action", "chimique", "mati√®re"],
    "histoire": ["civilisation", "soci√©t√©", "culture", "r√©volution"]
}

# === FONCTIONS UTILITAIRES ===
def compute_similarity(a, b):
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    if not a or not b:
        return 0.0
    vect = TfidfVectorizer()
    tfidf = vect.fit_transform([a, b])
    return float(cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0])

DEGREE_LEVEL_SCORES = {
    "Certificat": 0.7, "Licence": 0.9, "Ma√Ætrise": 1.0, "Master": 1.0, "Doctorat": 1.2
}

PRESTIGIOUS_SCHOOLS = ["Polytechnique", "Sorbonne", "HEC", "CentraleSup√©lec", "√âcole 42"]

def compute_degree_score(diplomas):
    if not diplomas:
        return 1.0
    return np.mean([DEGREE_LEVEL_SCORES.get(d.get("level", ""), 1.0) for d in diplomas])

def compute_prestige_score(experiences):
    if not experiences:
        return 1.0
    scores = [1.2 if any(s in e.get("company", "") for s in PRESTIGIOUS_SCHOOLS) else 1.0 for e in experiences]
    return np.mean(scores)

def extract_domain_from_text(text):
    text = text.lower()
    for d, words in DOMAIN_KEYWORDS.items():
        if any(w in text for w in words):
            return d
    return "autre"

# === G√âN√âRATION SYNTH√âTIQUE ===
df = pd.read_json("data_train_nettoye.json")

def simulate_course_pairings(df):
    simulated = []
    for _, prof in df.iterrows():
        desc = prof.get("description", "")
        diplomas = prof.get("diplomas", [])
        experiences = prof.get("experiences", [])
        pastCourses = prof.get("pastCourses", [])
        profile_text = " ".join([
            desc,
            " ".join(d.get("title", "") for d in diplomas),
            " ".join(e.get("title", "") for e in experiences),
            " ".join(c.get("title", "") for c in pastCourses)
        ])

        prof_domain = extract_domain_from_text(profile_text)
        avg_stars = np.mean([c.get("numberOfStars", 4.0) for c in pastCourses])

        for course_domain, keywords in DOMAIN_KEYWORDS.items():
            course_text = " ".join(keywords)
            similarity = compute_similarity(profile_text, course_text)
            base_note = 4.5 if course_domain == prof_domain else 2.7
            note = np.clip(base_note + np.random.normal(0, 0.3), 1.0, 5.0)

            simulated.append({
                "professor_id": prof.get("professor_id", None),
                "prof_domain": prof_domain,
                "course_domain": course_domain,
                "similarity": similarity,
                "degree_score": compute_degree_score(diplomas),
                "prestige_score": compute_prestige_score(experiences),
                "n_experiences": len(experiences),
                "n_diplomas": len(diplomas),
                "avg_stars": avg_stars,
                "target": round(note, 2)
            })
    return pd.DataFrame(simulated)

synthetic_df = simulate_course_pairings(df)
print(f"‚úÖ Donn√©es synth√©tiques g√©n√©r√©es : {synthetic_df.shape}")
synthetic_df.head()

# ==========================================
# üßÆ ENTRA√éNEMENT DU MOD√àLE CONTEXTUEL
# ==========================================

synthetic_df = pd.get_dummies(synthetic_df, columns=["prof_domain", "course_domain"])

X = synthetic_df.drop(columns=["target", "professor_id"])
y = synthetic_df["target"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = GradientBoostingRegressor(
    n_estimators=400, learning_rate=0.05, max_depth=5, random_state=42
)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print(f"‚úÖ MAE = {mean_absolute_error(y_test, y_pred):.3f}, R¬≤ = {r2_score(y_test, y_pred):.3f}")

joblib.dump(model, "models/model_contextual_realistic.pkl")
print("üì¶ Mod√®le sauvegard√© dans models/model_contextual_realistic.pkl")

# ==========================================
# üîÆ SIMULATION : PROF D‚ÄôINFORMATIQUE SUR COURS DE FRAN√áAIS
# ==========================================

prof = {
    "fistname": "Jean-Luc",
    "lastname": "Bernard",
    "city": "Paris",
    "description": "Formateur exp√©riment√© en d√©veloppement web et programmation.",
    "diplomas": [
        {"title": "Master en Informatique", "level": "Master"},
        {"title": "Licence en Informatique", "level": "Licence"}
    ],
    "experiences": [
        {"title": "Professeur d'Informatique", "company": "Universit√© de Lyon"},
        {"title": "Formateur Web", "company": "√âcole 42"}
    ],
    "pastCourses": [
        {"title": "Programmation Python", "description": "Cours de base sur Python.", "numberOfStars": 4.7},
        {"title": "D√©veloppement Web avec React", "description": "Cours pratique sur React.", "numberOfStars": 4.6}
    ]
}

course = {
    "title": "Analyse Litt√©raire et R√©daction",
    "description": "Cours de langue et d‚Äôanalyse de textes litt√©raires fran√ßais."
}

# Construction du profil complet
profile_text = " ".join([
    prof["description"],
    " ".join(d["title"] for d in prof["diplomas"]),
    " ".join(e["title"] for e in prof["experiences"]),
    " ".join(c["title"] for c in prof["pastCourses"])
])

prof_domain = extract_domain_from_text(profile_text)
course_domain = extract_domain_from_text(course["description"])
similarity = compute_similarity(profile_text, f"{course['title']} {course['description']}")

features = {
    "similarity": similarity,
    "degree_score": compute_degree_score(prof["diplomas"]),
    "prestige_score": compute_prestige_score(prof["experiences"]),
    "n_experiences": len(prof["experiences"]),
    "n_diplomas": len(prof["diplomas"]),
    "avg_stars": np.mean([c["numberOfStars"] for c in prof["pastCourses"]])
}

for d in DOMAIN_KEYWORDS.keys():
    features[f"prof_domain_{d}"] = 1 if d == prof_domain else 0
    features[f"course_domain_{d}"] = 1 if d == course_domain else 0

X_pred = pd.DataFrame([features])
for col in model.feature_names_in_:
    if col not in X_pred.columns:
        X_pred[col] = 0
X_pred = X_pred[model.feature_names_in_]

pred = model.predict(X_pred)[0]
print(f"‚≠ê Note pr√©dite : {round(pred, 2)}/5 pour un prof de {prof_domain} enseignant {course_domain}")

# ==========================================
# üíæ SAUVEGARDE ET T√âL√âCHARGEMENT DU MOD√àLE
# ==========================================
from google.colab import files
import shutil

# Nom du mod√®le (√† adapter selon ton entra√Ænement)
MODEL_NAME = "model_contextual_realistic.pkl"

# V√©rifie que le fichier existe
import os
if not os.path.exists(MODEL_NAME):
    raise FileNotFoundError(f"‚ùå Le mod√®le {MODEL_NAME} n'existe pas dans le dossier courant.")

# T√©l√©chargement direct depuis Colab
files.download(MODEL_NAME)

print(f"‚úÖ Mod√®le {MODEL_NAME} pr√™t √† √™tre t√©l√©charg√© sur ton ordinateur !")