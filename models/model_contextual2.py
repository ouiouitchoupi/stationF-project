# -*- coding: utf-8 -*-
"""model_contextual.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12R2abHr7Q_25GZZ9Tv0Sf2IzbfCzw3KC
"""

!pip install pandas scikit-learn matplotlib seaborn joblib

# ==========================================
# üöÄ IMPORTS ET CHARGEMENT DU DATASET
# ==========================================

from google.colab import files
uploaded = files.upload()  # ‚Üê charge ton data_train_nettoye.json

import pandas as pd
import numpy as np
import random
import joblib
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# NLP
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Visualisation
import matplotlib.pyplot as plt

# Chargement du dataset
DATA_PATH = list(uploaded.keys())[0]
df = pd.read_json(DATA_PATH)
print(f"‚úÖ Dataset charg√© ({len(df)} lignes)")
df.head(2)

# === R√©f√©rentiels de domaines ===
DOMAIN_KEYWORDS = {
    "informatique": ["programmation", "d√©veloppement", "python", "web", "java", "ia", "html", "css"],
    "maths": ["alg√®bre", "analyse", "probabilit√©s", "statistiques"],
    "fran√ßais": ["litt√©rature", "r√©daction", "grammaire", "langue"],
    "physique": ["√©lectricit√©", "m√©canique", "thermodynamique"],
    "chimie": ["mol√©cule", "r√©action", "chimique", "mati√®re"],
    "histoire": ["civilisation", "soci√©t√©", "culture", "r√©volution"]
}

DEGREE_LEVEL_SCORES = {
    "Certificat": 0.7, "Licence": 0.9, "Ma√Ætrise": 1.0, "Master": 1.0, "Doctorat": 1.2
}

PRESTIGIOUS_SCHOOLS = ["Polytechnique", "Sorbonne", "HEC", "CentraleSup√©lec", "√âcole 42"]

# === Fonctions utilitaires ===
def compute_similarity(a, b):
    if not a or not b:
        return 0.0
    vect = TfidfVectorizer()
    tfidf = vect.fit_transform([a, b])
    return float(cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0])

def compute_degree_score(diplomas):
    if not diplomas:
        return 1.0
    return np.mean([DEGREE_LEVEL_SCORES.get(d.get("level", ""), 1.0) for d in diplomas])

def compute_prestige_score(experiences):
    if not experiences:
        return 1.0
    scores = [1.2 if any(s in e.get("company", "") for s in PRESTIGIOUS_SCHOOLS) else 1.0 for e in experiences]
    return np.mean(scores)

def extract_domain_from_text(text):
    text = text.lower()
    scores = {d: sum(k in text for k in kws) for d, kws in DOMAIN_KEYWORDS.items()}
    return max(scores, key=scores.get)

# === G√©n√©ration des features ===
def extract_features_from_professor(prof, course_title, course_desc):
    """Construit les features d'un professeur + cours simul√© (format JSON API)."""
    desc = prof.get("description", "")
    diplomas = prof.get("diplomas", [])
    experiences = prof.get("experiences", [])
    pastCourses = prof.get("pastCourses", [])

    profile_text = " ".join([
        desc,
        " ".join(d.get("title", "") for d in diplomas),
        " ".join(e.get("title", "") for e in experiences),
        " ".join(c.get("title", "") for c in pastCourses)
    ])

    prof_domain = extract_domain_from_text(profile_text)
    course_domain = extract_domain_from_text(course_desc)
    similarity = compute_similarity(profile_text, f"{course_title} {course_desc}")

    degree_score = compute_degree_score(diplomas)
    prestige_score = compute_prestige_score(experiences)
    avg_stars = np.mean([c.get("numberOfStars", 4.0) for c in pastCourses])

    return {
        "similarity": similarity,
        "degree_score": degree_score,
        "prestige_score": prestige_score,
        "avg_stars": avg_stars,
        "prof_domain": prof_domain,
        "course_domain": course_domain
    }

# === Simulation r√©aliste des combinaisons prof / cours ===
def simulate_dataset(df):
    simulated = []
    for _, prof in df.iterrows():
        for domain_name, keywords in DOMAIN_KEYWORDS.items():
            course_title = f"Cours sur {domain_name.capitalize()}"
            course_desc = " ".join(keywords)
            feats = extract_features_from_professor(prof, course_title, course_desc)

            # Note simul√©e : forte si domaines corr√©l√©s
            base_note = 4.5 if feats["prof_domain"] == domain_name else 2.6
            note = np.clip(base_note + np.random.normal(0, 0.3), 1.0, 5.0)

            feats["target"] = round(note, 2)
            simulated.append(feats)
    return pd.DataFrame(simulated)

synthetic_df = simulate_dataset(df)
print(f"‚úÖ Donn√©es simul√©es g√©n√©r√©es : {synthetic_df.shape}")
synthetic_df.head()

# ==========================================
# üßÆ ENTRA√éNEMENT DU MOD√àLE RANDOM FOREST
# ==========================================

# One-hot encoding des domaines
synthetic_df = pd.get_dummies(synthetic_df, columns=["prof_domain", "course_domain"])

X = synthetic_df.drop(columns=["target"])
y = synthetic_df["target"]

# Split train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Entra√Ænement Random Forest
model = RandomForestRegressor(
    n_estimators=500,
    max_depth=10,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42,
    n_jobs=-1
)
model.fit(X_train, y_train)

# √âvaluation
y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"‚úÖ Mod√®le entra√Æn√© : MAE={mae:.3f}, R¬≤={r2:.3f}")

# Sauvegarde
MODEL_PATH = Path("models/model_contextual_randomforest.pkl")
MODEL_PATH.parent.mkdir(exist_ok=True)
joblib.dump(model, MODEL_PATH)
print(f"üì¶ Mod√®le sauvegard√© : {MODEL_PATH.as_posix()}")

# ==========================================
# üîÆ TEST DU MOD√àLE AVEC UN PROFESSEUR ET UN COURS (FORMAT API)
# ==========================================

professor = {
    "fistname": "Claire",
    "lastname": "Petit",
    "city": "Toulouse",
    "description": "Enseignante en math√©matiques appliqu√©es et statistiques.",
    "diplomas": [
        {"level": "Master", "title": "Master en Math√©matiques Appliqu√©es"},
        {"level": "Doctorat", "title": "Doctorat en Math√©matiques"}
    ],
    "experiences": [
        {"company": "Universit√© de Paris", "title": "Professeur de Math√©matiques"},
        {"company": "Universit√© de Paris", "title": "Chercheur en Statistiques"}
    ],
    "pastCourses": [
        {"title": "Statistiques", "description": "Cours sur les statistiques avanc√©es.", "numberOfStars": 4.4},
        {"title": "Analyse Math√©matique", "description": "Cours sur l‚Äôanalyse math√©matique.", "numberOfStars": 4.0}
    ]
}

course = {
    "title": "Programmation Python",
    "description": "Cours complet sur la programmation Python, les boucles et les structures de donn√©es."
}

# === Extraction des features ===
features = extract_features_from_professor(professor, course["title"], course["description"])

# One-hot encoding identique au mod√®le
for d in DOMAIN_KEYWORDS.keys():
    features[f"prof_domain_{d}"] = 1 if features["prof_domain"] == d else 0
    features[f"course_domain_{d}"] = 1 if features["course_domain"] == d else 0

# Pr√©paration du DataFrame
X_pred = pd.DataFrame([{k: v for k, v in features.items() if not isinstance(v, str)}])

for col in model.feature_names_in_:
    if col not in X_pred.columns:
        X_pred[col] = 0
X_pred = X_pred[model.feature_names_in_]

# Pr√©diction
pred = model.predict(X_pred)[0]
print(f"‚≠ê Note pr√©dite : {round(pred, 2)}/5 pour un prof de {features['prof_domain']} enseignant {features['course_domain']}")